{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdf83dd8",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e558c533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyrouge --upgrade\n",
    "# !pip install https://github.com/bheinzerling/pyrouge/archive/master.zip\n",
    "# !pip install pyrouge\n",
    "# !pip show pyrouge\n",
    "# !git clone https://github.com/andersjo/pyrouge.git\n",
    "# from pyrouge import Rouge155\n",
    "# !pyrouge_set_rouge_path 'pyrouge/tools/ROUGE-1.5.5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f298b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install tensorboardX\n",
    "# !pip install easydict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de354ff",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20c59ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('KorBertSum/src')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from models import data_loader, model_builder\n",
    "from models.model_builder import Summarizer\n",
    "from others.logging import logger, init_logger\n",
    "from models.data_loader import load_dataset\n",
    "from transformers import BertConfig, BertTokenizer\n",
    "from tensorboardX import SummaryWriter\n",
    "from models.reporter import ReportMgr\n",
    "from models.stats import Statistics\n",
    "import easydict\n",
    "from multiprocessing.dummy import Pool as ThreadPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ff14f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _tally_parameters(model):\n",
    "    n_params = sum([p.nelement() for p in model.parameters()])\n",
    "    return n_params\n",
    "\n",
    "def build_trainer(args, device_id, model,\n",
    "                  optim):\n",
    "    \"\"\"\n",
    "    Simplify `Trainer` creation based on user `opt`s*\n",
    "    Args:\n",
    "        opt (:obj:`Namespace`): user options (usually from argument parsing)\n",
    "        model (:obj:`onmt.models.NMTModel`): the model to train\n",
    "        fields (dict): dict of fields\n",
    "        optim (:obj:`onmt.utils.Optimizer`): optimizer used during training\n",
    "        data_type (str): string describing the type of data\n",
    "            e.g. \"text\", \"img\", \"audio\"\n",
    "        model_saver(:obj:`onmt.models.ModelSaverBase`): the utility object\n",
    "            used to save the model\n",
    "    \"\"\"\n",
    "    device = \"cpu\" if args.visible_gpus == '-1' else \"cuda\"\n",
    "\n",
    "\n",
    "    grad_accum_count = args.accum_count\n",
    "    n_gpu = args.world_size\n",
    "\n",
    "    if device_id >= 0:\n",
    "        gpu_rank = int(args.gpu_ranks[device_id])\n",
    "    else:\n",
    "        gpu_rank = 0\n",
    "        n_gpu = 0\n",
    "\n",
    "    print('gpu_rank %d' % gpu_rank)\n",
    "\n",
    "    tensorboard_log_dir = args.model_path\n",
    "\n",
    "    writer = SummaryWriter(tensorboard_log_dir, comment=\"Unmt\")\n",
    "\n",
    "    report_manager = ReportMgr(args.report_every, start_time=-1, tensorboard_writer=writer)\n",
    "\n",
    "    trainer = Trainer(args, model, optim, grad_accum_count, n_gpu, gpu_rank, report_manager)\n",
    "\n",
    "    # print(tr)\n",
    "    if (model):\n",
    "        n_params = _tally_parameters(model)\n",
    "        logger.info('* number of parameters: %d' % n_params)\n",
    "\n",
    "    return trainer\n",
    "\n",
    "class Trainer(object):\n",
    "    \"\"\"\n",
    "    Class that controls the training process.\n",
    "\n",
    "    Args:\n",
    "            model(:py:class:`onmt.models.model.NMTModel`): translation model\n",
    "                to train\n",
    "            train_loss(:obj:`onmt.utils.loss.LossComputeBase`):\n",
    "               training loss computation\n",
    "            valid_loss(:obj:`onmt.utils.loss.LossComputeBase`):\n",
    "               training loss computation\n",
    "            optim(:obj:`onmt.utils.optimizers.Optimizer`):\n",
    "               the optimizer responsible for update\n",
    "            trunc_size(int): length of truncated back propagation through time\n",
    "            shard_size(int): compute loss in shards of this size for efficiency\n",
    "            data_type(string): type of the source input: [text|img|audio]\n",
    "            norm_method(string): normalization methods: [sents|tokens]\n",
    "            grad_accum_count(int): accumulate gradients this many times.\n",
    "            report_manager(:obj:`onmt.utils.ReportMgrBase`):\n",
    "                the object that creates reports, or None\n",
    "            model_saver(:obj:`onmt.models.ModelSaverBase`): the saver is\n",
    "                used to save a checkpoint.\n",
    "                Thus nothing will be saved if this parameter is None\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,  args, model,  optim,\n",
    "                  grad_accum_count=1, n_gpu=1, gpu_rank=1,\n",
    "                  report_manager=None):\n",
    "        # Basic attributes.\n",
    "        self.args = args\n",
    "        self.save_checkpoint_steps = args.save_checkpoint_steps\n",
    "        self.model = model\n",
    "        self.optim = optim\n",
    "        self.grad_accum_count = grad_accum_count\n",
    "        self.n_gpu = n_gpu\n",
    "        self.gpu_rank = gpu_rank\n",
    "        self.report_manager = report_manager\n",
    "\n",
    "        self.loss = torch.nn.BCELoss(reduction='none')\n",
    "        assert grad_accum_count > 0\n",
    "        # Set model in training mode.\n",
    "        if (model):\n",
    "            self.model.train()\n",
    "            \n",
    "    def summ(self, test_iter, step, cal_lead=False, cal_oracle=False):\n",
    "          \"\"\" Validate model.\n",
    "              valid_iter: validate data iterator\n",
    "          Returns:\n",
    "              :obj:`nmt.Statistics`: validation loss statistics\n",
    "          \"\"\"\n",
    "          # Set model in validating mode.\n",
    "          def _get_ngrams(n, text):\n",
    "              ngram_set = set()\n",
    "              text_length = len(text)\n",
    "              max_index_ngram_start = text_length - n\n",
    "              for i in range(max_index_ngram_start + 1):\n",
    "                  ngram_set.add(tuple(text[i:i + n]))\n",
    "              return ngram_set\n",
    "\n",
    "          def _block_tri(c, p):\n",
    "              tri_c = _get_ngrams(3, c.split())\n",
    "              for s in p:\n",
    "                  tri_s = _get_ngrams(3, s.split())\n",
    "                  if len(tri_c.intersection(tri_s))>0:\n",
    "                      return True\n",
    "              return False\n",
    "\n",
    "          if (not cal_lead and not cal_oracle):\n",
    "              self.model.eval()\n",
    "          stats = Statistics()\n",
    "\n",
    "          with torch.no_grad():\n",
    "              for batch in test_iter:\n",
    "                  src = batch.src\n",
    "                  labels = batch.labels\n",
    "                  segs = batch.segs\n",
    "                  clss = batch.clss\n",
    "                  mask = batch.mask\n",
    "                  mask_cls = batch.mask_cls\n",
    "\n",
    "                  if (cal_lead):\n",
    "                      selected_ids = [list(range(batch.clss.size(1)))] * batch.batch_size\n",
    "                  elif (cal_oracle):\n",
    "                      selected_ids = [[j for j in range(batch.clss.size(1)) if labels[i][j] == 1] for i in\n",
    "                                      range(batch.batch_size)]\n",
    "                  else:\n",
    "                      sent_scores, mask = self.model(src, segs, clss, mask, mask_cls)\n",
    "                      sent_scores = sent_scores + mask.float()\n",
    "                      sent_scores = sent_scores.cpu().data.numpy()\n",
    "                      selected_ids = np.argsort(-sent_scores, 1)\n",
    "          return selected_ids\n",
    "\n",
    "    def _gradient_accumulation(self, true_batchs, normalization, total_stats,\n",
    "                               report_stats):\n",
    "        if self.grad_accum_count > 1:\n",
    "            self.model.zero_grad()\n",
    "\n",
    "        for batch in true_batchs:\n",
    "            if self.grad_accum_count == 1:\n",
    "                self.model.zero_grad()\n",
    "\n",
    "            src = batch.src\n",
    "            labels = batch.labels\n",
    "            segs = batch.segs\n",
    "            clss = batch.clss\n",
    "            mask = batch.mask\n",
    "            mask_cls = batch.mask_cls\n",
    "\n",
    "            sent_scores, mask = self.model(src, segs, clss, mask, mask_cls)\n",
    "\n",
    "            loss = self.loss(sent_scores, labels.float())\n",
    "            loss = (loss*mask.float()).sum()\n",
    "            (loss/loss.numel()).backward()\n",
    "            # loss.div(float(normalization)).backward()\n",
    "\n",
    "            batch_stats = Statistics(float(loss.cpu().data.numpy()), normalization)\n",
    "\n",
    "\n",
    "            total_stats.update(batch_stats)\n",
    "            report_stats.update(batch_stats)\n",
    "\n",
    "            # 4. Update the parameters and statistics.\n",
    "            if self.grad_accum_count == 1:\n",
    "                # Multi GPU gradient gather\n",
    "                if self.n_gpu > 1:\n",
    "                    grads = [p.grad.data for p in self.model.parameters()\n",
    "                             if p.requires_grad\n",
    "                             and p.grad is not None]\n",
    "                    distributed.all_reduce_and_rescale_tensors(\n",
    "                        grads, float(1))\n",
    "                self.optim.step()\n",
    "\n",
    "        # in case of multi step gradient accumulation,\n",
    "        # update only after accum batches\n",
    "        if self.grad_accum_count > 1:\n",
    "            if self.n_gpu > 1:\n",
    "                grads = [p.grad.data for p in self.model.parameters()\n",
    "                         if p.requires_grad\n",
    "                         and p.grad is not None]\n",
    "                distributed.all_reduce_and_rescale_tensors(\n",
    "                    grads, float(1))\n",
    "            self.optim.step()\n",
    "            \n",
    "    def _save(self, step):\n",
    "        real_model = self.model\n",
    "        # real_generator = (self.generator.module\n",
    "        #                   if isinstance(self.generator, torch.nn.DataParallel)\n",
    "        #                   else self.generator)\n",
    "\n",
    "        model_state_dict = real_model.state_dict()\n",
    "        # generator_state_dict = real_generator.state_dict()\n",
    "        checkpoint = {\n",
    "            'model': model_state_dict,\n",
    "            # 'generator': generator_state_dict,\n",
    "            'opt': self.args,\n",
    "            'optim': self.optim,\n",
    "        }\n",
    "        checkpoint_path = os.path.join(self.args.model_path, 'model_step_%d.pt' % step)\n",
    "        logger.info(\"Saving checkpoint %s\" % checkpoint_path)\n",
    "        # checkpoint_path = '%s_step_%d.pt' % (FLAGS.model_path, step)\n",
    "        if (not os.path.exists(checkpoint_path)):\n",
    "            torch.save(checkpoint, checkpoint_path)\n",
    "            return checkpoint, checkpoint_path\n",
    "\n",
    "    def _start_report_manager(self, start_time=None):\n",
    "        \"\"\"\n",
    "        Simple function to start report manager (if any)\n",
    "        \"\"\"\n",
    "        if self.report_manager is not None:\n",
    "            if start_time is None:\n",
    "                self.report_manager.start()\n",
    "            else:\n",
    "                self.report_manager.start_time = start_time\n",
    "\n",
    "    def _maybe_gather_stats(self, stat):\n",
    "        \"\"\"\n",
    "        Gather statistics in multi-processes cases\n",
    "\n",
    "        Args:\n",
    "            stat(:obj:onmt.utils.Statistics): a Statistics object to gather\n",
    "                or None (it returns None in this case)\n",
    "\n",
    "        Returns:\n",
    "            stat: the updated (or unchanged) stat object\n",
    "        \"\"\"\n",
    "        if stat is not None and self.n_gpu > 1:\n",
    "            return Statistics.all_gather_stats(stat)\n",
    "        return stat\n",
    "\n",
    "    def _maybe_report_training(self, step, num_steps, learning_rate,\n",
    "                               report_stats):\n",
    "        \"\"\"\n",
    "        Simple function to report training stats (if report_manager is set)\n",
    "        see `onmt.utils.ReportManagerBase.report_training` for doc\n",
    "        \"\"\"\n",
    "        if self.report_manager is not None:\n",
    "            return self.report_manager.report_training(\n",
    "                step, num_steps, learning_rate, report_stats,\n",
    "                multigpu=self.n_gpu > 1)\n",
    "        \n",
    "    def _report_step(self, learning_rate, step, train_stats=None,\n",
    "                     valid_stats=None):\n",
    "        \"\"\"\n",
    "        Simple function to report stats (if report_manager is set)\n",
    "        see `onmt.utils.ReportManagerBase.report_step` for doc\n",
    "        \"\"\"\n",
    "        if self.report_manager is not None:\n",
    "            return self.report_manager.report_step(\n",
    "                learning_rate, step, train_stats=train_stats,\n",
    "                valid_stats=valid_stats)\n",
    "\n",
    "    def _maybe_save(self, step):\n",
    "        \"\"\"\n",
    "        Save the model if a model saver is set\n",
    "        \"\"\"\n",
    "        if self.model_saver is not None:\n",
    "            self.model_saver.maybe_save(step)\n",
    "\n",
    "class BertData():\n",
    "    def __init__(self):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "        self.sep_vid = self.tokenizer.vocab['[SEP]']\n",
    "        self.cls_vid = self.tokenizer.vocab['[CLS]']\n",
    "        self.pad_vid = self.tokenizer.vocab['[PAD]']\n",
    "\n",
    "    def preprocess(self, src):\n",
    "\n",
    "        if (len(src) == 0):\n",
    "            return None\n",
    "\n",
    "        original_src_txt = [' '.join(s) for s in src]\n",
    "        idxs = [i for i, s in enumerate(src) if (len(s) > 1)]\n",
    "\n",
    "        src = [src[i][:2000] for i in idxs]\n",
    "        src = src[:1000]\n",
    "\n",
    "        if (len(src) < 3):\n",
    "            return None\n",
    "\n",
    "        src_txt = [' '.join(sent) for sent in src]\n",
    "        text = ' [SEP] [CLS] '.join(src_txt)\n",
    "        src_subtokens = self.tokenizer.tokenize(text)\n",
    "        src_subtokens = src_subtokens[:510]\n",
    "        src_subtokens = ['[CLS]'] + src_subtokens + ['[SEP]']\n",
    "\n",
    "        src_subtoken_idxs = self.tokenizer.convert_tokens_to_ids(src_subtokens)\n",
    "        _segs = [-1] + [i for i, t in enumerate(src_subtoken_idxs) if t == self.sep_vid]\n",
    "        segs = [_segs[i] - _segs[i - 1] for i in range(1, len(_segs))]\n",
    "        segments_ids = []\n",
    "        for i, s in enumerate(segs):\n",
    "            if (i % 2 == 0):\n",
    "                segments_ids += s * [0]\n",
    "            else:\n",
    "                segments_ids += s * [1]\n",
    "        cls_ids = [i for i, t in enumerate(src_subtoken_idxs) if t == self.cls_vid]\n",
    "        labels = None\n",
    "        src_txt = [original_src_txt[i] for i in idxs]\n",
    "        tgt_txt = None\n",
    "        return src_subtoken_idxs, labels, segments_ids, cls_ids, src_txt, tgt_txt\n",
    "    \n",
    "def _lazy_dataset_loader(pt_file):\n",
    "  yield  pt_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af48cdb",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb66068a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-16 17:27:56,703 INFO] Loading checkpoint from ../models/bert_trans_1/model_step_65000.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Summarizer(\n",
       "  (bert): Bert(\n",
       "    (model): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder): TransformerInterEncoder(\n",
       "    (pos_emb): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer_inter): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (w_2): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (w_2): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (wo): Linear(in_features=768, out_features=1, bias=True)\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = easydict.EasyDict({\n",
    "    \"encoder\":'transformer', ## classifier or transformer\n",
    "    \"mode\":'test',\n",
    "    \"bert_data_path\":'../bert_data/korean',\n",
    "    \"model_path\":'../models/bert_trans_1', ## check\n",
    "    \"result_path\":'../results',\n",
    "    \"temp_dir\":'../temp',\n",
    "    \"batch_size\":1000,\n",
    "    \"use_interval\":True,\n",
    "    \"hidden_size\":128,\n",
    "    \"ff_size\":512,\n",
    "    \"heads\":4,\n",
    "    \"inter_layers\":2,\n",
    "    \"rnn_size\":512,\n",
    "    \"param_init\":0,\n",
    "    \"param_init_glorot\":True,\n",
    "    \"dropout\":0.1,\n",
    "    \"optim\":'adamW', ## check\n",
    "    \"lr\":2e-3,\n",
    "    \"report_every\":1,\n",
    "    \"save_checkpoint_steps\":100,\n",
    "    \"block_trigram\":True,\n",
    "    \"recall_eval\":False,\n",
    "    \n",
    "    \"accum_count\":1,\n",
    "    \"world_size\":1,\n",
    "    \"visible_gpus\":'0', # 0 = gpu, -1 = cpu ## check\n",
    "    \"gpu_ranks\":'0',\n",
    "    \"log_file\":'../logs/train_trans_1.txt', ## check\n",
    "    \"test_from\":'../models/bert_trans_1/model_step_65000.pt' ## check\n",
    "})\n",
    "model_flags = ['hidden_size', 'ff_size', 'heads', 'inter_layers','encoder','ff_actv', 'use_interval','rnn_size']\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "# Model Load\n",
    "# test(args, input_data, -1, '', None)\n",
    "pt = ''\n",
    "step = None\n",
    "\n",
    "init_logger(args.log_file)\n",
    "device = \"cpu\" if args.visible_gpus == '-1' else \"cuda\"\n",
    "device_id = 0 if device == \"cuda\" else -1\n",
    "\n",
    "cp = args.test_from\n",
    "try:\n",
    "    step = int(cp.split('.')[-2].split('_')[-1])\n",
    "except:\n",
    "    step = 0\n",
    "\n",
    "device = \"cpu\" if args.visible_gpus == '-1' else \"cuda\"\n",
    "if (pt != ''):\n",
    "    test_from = pt\n",
    "else:\n",
    "    test_from = args.test_from\n",
    "logger.info('Loading checkpoint from %s' % test_from)\n",
    "checkpoint = torch.load(test_from, map_location=lambda storage, loc: storage)\n",
    "opt = vars(checkpoint['opt'])\n",
    "for k in opt.keys():\n",
    "    if (k in model_flags):\n",
    "        setattr(args, k, opt[k])\n",
    "\n",
    "config = BertConfig.from_pretrained('bert-base-multilingual-cased')\n",
    "model = Summarizer(args, device, load_pretrained_bert=False, bert_config = config)\n",
    "model.load_cp(checkpoint)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76759015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, input_list):\n",
    "  test_iter = data_loader.Dataloader(args, _lazy_dataset_loader(input_list),\n",
    "                                args.batch_size, device,\n",
    "                                shuffle=False, is_test=True)\n",
    "  trainer = build_trainer(args, device_id, model, None)\n",
    "  result = trainer.summ(test_iter, step)\n",
    "  return result, input_list\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "def txt2input(text):\n",
    "  data = list(filter(None, text.split('\\n')))\n",
    "  bertdata = BertData()\n",
    "  txt_data = bertdata.preprocess(data)\n",
    "  data_dict = {\"src\":txt_data[0],\n",
    "               \"labels\":[0,1,2],\n",
    "               \"segs\":txt_data[2],\n",
    "               \"clss\":txt_data[3],\n",
    "               \"src_txt\":txt_data[4],\n",
    "               \"tgt_txt\":None}\n",
    "  input_data = []\n",
    "  input_data.append(data_dict)\n",
    "  return input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b05daf4",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d23f23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-16 17:28:08,929 INFO] Note: NumExpr detected 32 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>journal</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>627cdd2c7f98dd6342b32229</td>\n",
       "      <td>민주당-檢 ‘검수완박’ 충돌 더불어민주당이 15일 이른바 ‘검수완박’(검찰 수사권 ...</td>\n",
       "      <td>2022-04-16</td>\n",
       "      <td>동아일보</td>\n",
       "      <td>민주당-檢 ‘검수완박’ 충돌 더불어민주당이 15일 이른바 ‘검수완박’(검찰 수사권 ...</td>\n",
       "      <td>민주 172명 전원 ‘검수완박’ 법안 발의… 대검 “명백한 위헌”</td>\n",
       "      <td>https://www.donga.com/news/Politics/article/al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>627cdd4d7f98dd6342b3222e</td>\n",
       "      <td>민주, ‘정호영 자녀 의혹’ 경북대병원 현장조사 정호영 보건복지부 장관 후보자의 자...</td>\n",
       "      <td>2022-04-16</td>\n",
       "      <td>동아일보</td>\n",
       "      <td>민주, ‘정호영 자녀 의혹’ 경북대병원 현장조사 정호영 보건복지부 장관 후보자의 자...</td>\n",
       "      <td>[단독]정호영 논문 공저자들, 딸 의대 편입 구술평가 만점 줘</td>\n",
       "      <td>https://www.donga.com/news/Society/article/all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>627cdd4d7f98dd6342b3225c</td>\n",
       "      <td>지난 15일 박병석 국회의장에게 검찰 수사권 완전 박탈 입법 추진의 부당성을 호소하...</td>\n",
       "      <td>2022-04-18</td>\n",
       "      <td>동아일보</td>\n",
       "      <td>지난 15일 박병석 국회의장에게 검찰 수사권 완전 박탈 입법 추진의 부당성을 호소하...</td>\n",
       "      <td>김오수 검찰총장, 민주당 검수완박에 항의 사표</td>\n",
       "      <td>https://www.donga.com/news/Society/article/all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>627cdd4d7f98dd6342b32263</td>\n",
       "      <td>정호영 보건복지부 장관 후보자가 자녀 관련 의혹 등을 설명하기 위해 17일 서울 중...</td>\n",
       "      <td>2022-04-19</td>\n",
       "      <td>동아일보</td>\n",
       "      <td>정호영 보건복지부 장관 후보자가 자녀 관련 의혹 등을 설명하기 위해 17일 서울 중...</td>\n",
       "      <td>정호영 동문 교수 3명, 아들-딸 서류전형도 최고점</td>\n",
       "      <td>https://www.donga.com/news/Society/article/all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>627cdd4d7f98dd6342b32268</td>\n",
       "      <td>크게보기 문재인 대통령은 2018년 6·13지방선거 압승 이후 ‘적폐 청산’이 본격...</td>\n",
       "      <td>2022-04-19</td>\n",
       "      <td>동아일보</td>\n",
       "      <td>크게보기 문재인 대통령은 2018년 6·13지방선거 압승 이후 ‘적폐 청산’이 본격...</td>\n",
       "      <td>두 전임 대통령이 윤석열 당선인에게 주는 교훈[동아광장/한규섭]</td>\n",
       "      <td>https://www.donga.com/news/Opinion/article/all...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  \\\n",
       "0  627cdd2c7f98dd6342b32229   \n",
       "1  627cdd4d7f98dd6342b3222e   \n",
       "2  627cdd4d7f98dd6342b3225c   \n",
       "3  627cdd4d7f98dd6342b32263   \n",
       "4  627cdd4d7f98dd6342b32268   \n",
       "\n",
       "                                             content        date journal  \\\n",
       "0  민주당-檢 ‘검수완박’ 충돌 더불어민주당이 15일 이른바 ‘검수완박’(검찰 수사권 ...  2022-04-16    동아일보   \n",
       "1  민주, ‘정호영 자녀 의혹’ 경북대병원 현장조사 정호영 보건복지부 장관 후보자의 자...  2022-04-16    동아일보   \n",
       "2  지난 15일 박병석 국회의장에게 검찰 수사권 완전 박탈 입법 추진의 부당성을 호소하...  2022-04-18    동아일보   \n",
       "3  정호영 보건복지부 장관 후보자가 자녀 관련 의혹 등을 설명하기 위해 17일 서울 중...  2022-04-19    동아일보   \n",
       "4  크게보기 문재인 대통령은 2018년 6·13지방선거 압승 이후 ‘적폐 청산’이 본격...  2022-04-19    동아일보   \n",
       "\n",
       "                                             summary  \\\n",
       "0  민주당-檢 ‘검수완박’ 충돌 더불어민주당이 15일 이른바 ‘검수완박’(검찰 수사권 ...   \n",
       "1  민주, ‘정호영 자녀 의혹’ 경북대병원 현장조사 정호영 보건복지부 장관 후보자의 자...   \n",
       "2  지난 15일 박병석 국회의장에게 검찰 수사권 완전 박탈 입법 추진의 부당성을 호소하...   \n",
       "3  정호영 보건복지부 장관 후보자가 자녀 관련 의혹 등을 설명하기 위해 17일 서울 중...   \n",
       "4  크게보기 문재인 대통령은 2018년 6·13지방선거 압승 이후 ‘적폐 청산’이 본격...   \n",
       "\n",
       "                                   title  \\\n",
       "0  민주 172명 전원 ‘검수완박’ 법안 발의… 대검 “명백한 위헌”    \n",
       "1    [단독]정호영 논문 공저자들, 딸 의대 편입 구술평가 만점 줘    \n",
       "2             김오수 검찰총장, 민주당 검수완박에 항의 사표    \n",
       "3          정호영 동문 교수 3명, 아들-딸 서류전형도 최고점    \n",
       "4   두 전임 대통령이 윤석열 당선인에게 주는 교훈[동아광장/한규섭]    \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.donga.com/news/Politics/article/al...  \n",
       "1  https://www.donga.com/news/Society/article/all...  \n",
       "2  https://www.donga.com/news/Society/article/all...  \n",
       "3  https://www.donga.com/news/Society/article/all...  \n",
       "4  https://www.donga.com/news/Opinion/article/all...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### DB 검색어 데이터셋 가져오기\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "res = requests.get('http://ec2-3-34-47-218.ap-northeast-2.compute.amazonaws.com:5000/news?query=' + '민주당') # 검색어 바꾸기\n",
    "news_dict = json.loads(res.text) # list 안에 딕셔너리 형태\n",
    "\n",
    "col_name = [\"_id\", \"content\", \"date\", \"journal\", \"summary\", \"title\", \"url\"]\n",
    "news_df = pd.DataFrame(news_dict, columns=col_name)\n",
    "\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17ed0f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NaN'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.loc[930][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cec8090",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 979/979 [00:00<00:00, 1283.94it/s]\n",
      "100%|██████████| 979/979 [00:00<00:00, 5428.43it/s]\n"
     ]
    }
   ],
   "source": [
    "### 동아일보 들여쓰기\n",
    "from tqdm import tqdm\n",
    "from more_itertools import locate\n",
    "\n",
    "new_list = []\n",
    "\n",
    "for i in tqdm(range(len(news_df))):\n",
    "    idx = news_df.loc[i]['_id']\n",
    "    test_txt = news_df.loc[i]['content']\n",
    "    date = news_df.loc[i]['date']\n",
    "    journal = news_df.loc[i]['journal']\n",
    "    summary = news_df.loc[i]['summary']\n",
    "    title = news_df.loc[i]['title']\n",
    "    url = news_df.loc[i]['url']\n",
    "        \n",
    "    if journal == '동아일보':\n",
    "        # 문장 끝 부호 인덱스 구하기\n",
    "        pos_1 = list(locate(test_txt, (lambda x: x == \".\")))\n",
    "        pos_2 = list(locate(test_txt, (lambda x: x == \"?\")))\n",
    "        pos_3 = list(locate(test_txt, (lambda x: x == \"!\")))\n",
    "\n",
    "        pos = (pos_1 + pos_2 + pos_3)\n",
    "        pos.sort()\n",
    "        \n",
    "        # 문장별 리스트로 쪼개기\n",
    "        txts = []\n",
    "        for i in range(len(pos)):\n",
    "            if i == 0:\n",
    "                txts.append(test_txt[:(pos[i]+1)])\n",
    "            elif i == (len(pos)-1):\n",
    "                txts.append(test_txt[(pos[i-1]+1):(pos[i]+1)])\n",
    "                txts.append(test_txt[(pos[i]+1):])\n",
    "            else:\n",
    "                txts.append(test_txt[(pos[i-1]+1):(pos[i]+1)])\n",
    "                \n",
    "        # \\n 추가\n",
    "        # 쪼개서 추가하는 이유.. 확인하고 바로 \\n 추가하면 인덱스가 달라져서..\n",
    "        txt = \"\"\n",
    "        for i in range(1, len(txts)):\n",
    "            if len(txts[i]) == 0:\n",
    "                continue\n",
    "            elif txts[i][0] != \" \":\n",
    "                txts[i - 1] += \"\\n\\n\"\n",
    "\n",
    "        # 문장 하나로 합치기\n",
    "        for i in range(len(txts)):\n",
    "            txt += txts[i]\n",
    "        \n",
    "        # Df에서 바로 변경하고 싶었지만, 변경되지 않아서 새로 만듦\n",
    "        new_list.append(\n",
    "            {\n",
    "                \"_id\" : idx,\n",
    "                \"content\" : txt,\n",
    "                \"date\" : date,\n",
    "                \"journal\" : journal,\n",
    "                \"summary\" : summary,\n",
    "                \"title\" : title,\n",
    "                \"url\" : url\n",
    "            }\n",
    "        )\n",
    "    else: # 한겨레일 때\n",
    "        new_list.append(\n",
    "            {\n",
    "                \"_id\" : idx,\n",
    "                \"content\" : test_txt,\n",
    "                \"date\" : date,\n",
    "                \"journal\" : journal,\n",
    "                \"summary\" : summary,\n",
    "                \"title\" : title,\n",
    "                \"url\" : url\n",
    "            }\n",
    "        )\n",
    "\n",
    "col_name = [\"_id\", \"content\", \"date\", \"journal\", \"summary\", \"title\", \"url\"]\n",
    "news_df_test = pd.DataFrame(new_list, columns=col_name)\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "### 리스트 생성\n",
    "idxs = news_df_test['_id'].tolist()\n",
    "texts = news_df_test['content'].tolist()\n",
    "summaries = news_df_test['summary'].tolist()\n",
    "idx_text = list(zip(idxs, texts, summaries))\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "# # 기준 정하기\n",
    "# print(len('박임근 기자 hanjeoung990111@kookmin.ac.kr'))\n",
    "# print(len('지난해 3월 만경강 도보여행길 걷기에 앞서 발원지인 밤샘에서 촬영한 모습. 박영환씨 제공'))\n",
    "# 논문에서 50 미만 제거 함\n",
    "\n",
    "# 문자열 길이 확인 및 제거 & 기자 및 이메일 제거\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "for i in tqdm(range(len(idx_text))):\n",
    "    idx_text[i] = list(idx_text[i])\n",
    "    if (idx_text[i][1] != \"\"):\n",
    "        if (isinstance(idx_text[i][1], str)):\n",
    "            text_list = idx_text[i][1].split('\\n')\n",
    "            re_text = ''\n",
    "\n",
    "            for text in (text_list):\n",
    "                if len(text) > 50:\n",
    "                    text = re.sub(r\"([\\w\\.-]+)@([\\w\\.-]+)(\\.[\\w\\.]+)\", \"\", text) # 이메일 검사\n",
    "\n",
    "                    if \" 기자\" in text: # 기자 검사\n",
    "                        repoter_check = text.split(\" \")\n",
    "                        while \"기자\" in repoter_check:\n",
    "                            index = repoter_check.index(\"기자\")\n",
    "                            del repoter_check[index]\n",
    "                            del repoter_check[index-1]\n",
    "                        text = ' '.join(r for r in repoter_check)\n",
    "\n",
    "                    re_text += (text + '\\n')\n",
    "\n",
    "            idx_text[i][1] = re_text\n",
    "        \n",
    "    else:\n",
    "        idx_text[i][1] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8a06bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['627cdd4d7f98dd6342b33b58',\n",
       " '조 바이든 미국 대통령이 9일 제2차 세계대전이 한창이던 1941년 이후 81년 만에 외국에 무기를 지원할 때 별도의 행정절차를 거치지 않아도 되는 ‘무기 대여법’에 서명하며 우크라이나 지원에 박차를 가했다. 같은 날 러시아군 역시 우크라이나 남부 흑해 연안의 요충지 오데사에 극초음속 미사일 ‘킨잘’ 3발을 발사하는 등 대규모 공격을 가했다. 이로 인해 당시 오데사를 방문 중이던 샤를 미셸 유럽연합(EU) 정상회의 상임 의장이 긴급 대피했다.\\n바이든 대통령은 이날 백악관에서 “미국은 블라디미르 푸틴 러시아 대통령의 잔혹한 전쟁에 맞서 민주주의와 조국을 지키려는 우크라이나의 투쟁을 지지한다”며 무기 대여법에 서명했다. 이어 “우크라이나에 지원할 예산이 10일 뒤면 바닥날 것”이라며 미 의회에 추가 예산 승인도 촉구했다.\\n현재 미 국방부가 보유한 우크라이나 지원 예산 잔액은 약 1억 달러(약 1273억 원)로 곧 소진될 가능성이 높다. 집권 민주당은 당초 바이든 대통령이 요청한 330억 달러의 지원 예산에 인도적 지원 예산 등을 포함해 총 398억 달러(약 51조 원)의 우크라이나 지원 예산을 빠르면 10일 표결에 부치기로 했다.\\nCNN 등에 따르면 러시아군은 9일 내내 오데사에 대한 미사일 공격을 단행했다. 킨잘 외에도 오닉스 순항미사일, 폭격기 등이 동원됐다. 중심가의 한 쇼핑센터에서는 거대한 폭발음과 화염도 나타났다. 오데사를 거쳐 돈바스 등으로 공급되는 서방 무기를 차단하기 위한 목적이라는 분석이 나온다. 이날 오데사를 깜짝 방문한 미셸 의장 또한 미사일 공격을 피해 방공호로 잠시 대피하는 소동 속에서도 우크라이나를 지원할 뜻을 강조했다.\\n',\n",
       " 'NaN']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_text[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4541ba8",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "add090ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plink failed to import tkinter.\n"
     ]
    }
   ],
   "source": [
    "## DB 연결\n",
    "\n",
    "from bson.objectid import ObjectId\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient(\"mongodb+srv://BaekYeonsun:hello12345@cluster.3dypr.mongodb.net/database?retryWrites=true&w=majority\")\n",
    "collection = client.database.news\n",
    "\n",
    "# collection.update_one({'_id': ObjectId('627cdd2c7f98dd6342b32229')}, {'$set': {'summary':'test'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bf7d322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def inference(texts):\n",
    "    time.sleep(1)\n",
    "    idx = texts[0]\n",
    "    text = texts[1]\n",
    "    summary = texts[2]\n",
    "    \n",
    "    if(summary == 'NaN'): # 요약이 nan 값인 경우\n",
    "        if text == \"\" or pd.isna(text):\n",
    "            collection.update_one({'_id': ObjectId(idx)}, {'$set': {'summary':''}})\n",
    "        else:\n",
    "            if len(text.split('\\n')) <= 3: # 원문 기사가 짧은 경우. txt2input에서 none 타입이 됨\n",
    "                collection.update_one({'_id': ObjectId(idx)}, {'$set': {'summary': text}})\n",
    "            else:\n",
    "                input_data = txt2input(text)\n",
    "                sum_list = test(args, input_data)\n",
    "                result = [list(filter(None, text.split('\\n')))[i] for i in sum_list[0][0][:2]]\n",
    "                try:\n",
    "                    summary = (result[0] + \" \" + result[1])\n",
    "                    collection.update_one({'_id': ObjectId(idx)}, {'$set': {'summary': summary}})\n",
    "                except:\n",
    "                    summary = (result[0])\n",
    "                    collection.update_one({'_id': ObjectId(idx)}, {'$set': {'summary': summary}})\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d136cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 901/979 [00:19<00:01, 49.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-16 17:31:35,846 INFO] * number of parameters: 184162049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n",
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-16 17:31:40,000 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 17:31:40,613 INFO] * number of parameters: 184162049\n",
      " 92%|█████████▏| 901/979 [00:31<00:01, 49.90it/s][2022-05-16 17:31:41,648 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 17:31:42,352 INFO] * number of parameters: 184162049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-16 17:31:43,151 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 17:31:43,185 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 17:31:43,357 INFO] * number of parameters: 184162049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-16 17:31:44,370 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 17:31:44,507 INFO] * number of parameters: 184162049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-16 17:31:46,204 INFO] * number of parameters: 184162049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 931/979 [00:43<00:08,  5.51it/s][2022-05-16 17:31:52,604 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 17:31:47,052 INFO] * number of parameters: 184162049\n",
      " 95%|█████████▌| 932/979 [00:44<00:08,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n",
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-16 17:31:47,601 INFO] * number of parameters: 184162049\n",
      " 96%|█████████▌| 936/979 [00:45<00:08,  5.23it/s][2022-05-16 17:31:48,110 INFO] * number of parameters: 184162049\n",
      " 96%|█████████▌| 939/979 [00:46<00:07,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-16 17:31:48,555 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 17:31:49,120 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 17:31:49,639 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 17:31:49,722 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 17:31:49,751 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 17:31:49,763 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 17:31:49,765 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 17:31:49,825 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 17:31:49,925 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 17:31:50,031 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 17:31:50,034 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 17:31:50,187 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 17:31:50,222 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 17:31:50,455 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 17:31:50,856 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 17:31:50,878 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 17:31:51,015 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 17:31:51,375 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 17:31:51,398 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 17:31:51,418 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 17:31:51,761 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 17:31:51,818 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 17:31:52,193 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 17:31:46,977 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 17:31:54,472 INFO] * number of parameters: 184162049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n",
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-16 17:31:54,852 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 17:31:55,167 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 17:31:55,227 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 17:31:55,237 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 17:31:55,667 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 17:31:55,669 INFO] * number of parameters: 184162049\n",
      " 96%|█████████▌| 942/979 [00:48<00:08,  4.41it/s][2022-05-16 17:31:55,672 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 17:31:55,674 INFO] * number of parameters: 184162049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-16 17:31:57,264 INFO] * number of parameters: 184162049\n",
      "100%|██████████| 979/979 [01:07<00:00, 14.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ThreadPool 방식\n",
    "pool = ThreadPool(50)\n",
    "\n",
    "for _ in tqdm(pool.imap_unordered(inference, idx_text), total=len(idx_text)):\n",
    "    pass\n",
    "    \n",
    "print(\"finish\")\n",
    "\n",
    "# pool.close()\n",
    "# pool.terminate()\n",
    "# pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45d5ea13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('627cdd4d7f98dd6342b33b58'),\n",
       " 'content': '조 바이든 미국 대통령이 9일 제2차 세계대전이 한창이던 1941년 이후 81년 만에 외국에 무기를 지원할 때 별도의 행정절차를 거치지 않아도 되는 ‘무기 대여법’에 서명하며 우크라이나 지원에 박차를 가했다. 같은 날 러시아군 역시 우크라이나 남부 흑해 연안의 요충지 오데사에 극초음속 미사일 ‘킨잘’ 3발을 발사하는 등 대규모 공격을 가했다. 이로 인해 당시 오데사를 방문 중이던 샤를 미셸 유럽연합(EU) 정상회의 상임 의장이 긴급 대피했다.바이든 대통령은 이날 백악관에서 “미국은 블라디미르 푸틴 러시아 대통령의 잔혹한 전쟁에 맞서 민주주의와 조국을 지키려는 우크라이나의 투쟁을 지지한다”며 무기 대여법에 서명했다. 이어 “우크라이나에 지원할 예산이 10일 뒤면 바닥날 것”이라며 미 의회에 추가 예산 승인도 촉구했다.현재 미 국방부가 보유한 우크라이나 지원 예산 잔액은 약 1억 달러(약 1273억 원)로 곧 소진될 가능성이 높다. 집권 민주당은 당초 바이든 대통령이 요청한 330억 달러의 지원 예산에 인도적 지원 예산 등을 포함해 총 398억 달러(약 51조 원)의 우크라이나 지원 예산을 빠르면 10일 표결에 부치기로 했다.CNN 등에 따르면 러시아군은 9일 내내 오데사에 대한 미사일 공격을 단행했다. 킨잘 외에도 오닉스 순항미사일, 폭격기 등이 동원됐다. 중심가의 한 쇼핑센터에서는 거대한 폭발음과 화염도 나타났다. 오데사를 거쳐 돈바스 등으로 공급되는 서방 무기를 차단하기 위한 목적이라는 분석이 나온다. 이날 오데사를 깜짝 방문한 미셸 의장 또한 미사일 공격을 피해 방공호로 잠시 대피하는 소동 속에서도 우크라이나를 지원할 뜻을 강조했다.워싱턴=문병기 특파원 weappon@donga.com',\n",
       " 'date': '2022-05-11',\n",
       " 'journal': '동아일보',\n",
       " 'summary': '바이든 대통령은 이날 백악관에서 “미국은 블라디미르 푸틴 러시아 대통령의 잔혹한 전쟁에 맞서 민주주의와 조국을 지키려는 우크라이나의 투쟁을 지지한다”며 무기 대여법에 서명했다. 이어 “우크라이나에 지원할 예산이 10일 뒤면 바닥날 것”이라며 미 의회에 추가 예산 승인도 촉구했다. 조 바이든 미국 대통령이 9일 제2차 세계대전이 한창이던 1941년 이후 81년 만에 외국에 무기를 지원할 때 별도의 행정절차를 거치지 않아도 되는 ‘무기 대여법’에 서명하며 우크라이나 지원에 박차를 가했다. 같은 날 러시아군 역시 우크라이나 남부 흑해 연안의 요충지 오데사에 극초음속 미사일 ‘킨잘’ 3발을 발사하는 등 대규모 공격을 가했다. 이로 인해 당시 오데사를 방문 중이던 샤를 미셸 유럽연합(EU) 정상회의 상임 의장이 긴급 대피했다.',\n",
       " 'title': '바이든, 2차대전때처럼 ‘우크라 무기대여법’ 서명',\n",
       " 'url': 'https://www.donga.com/news/Inter/article/all/20220510/113333845/1'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.find_one({'_id': ObjectId(idx_text[-1][0])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34c8c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Notebook)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
