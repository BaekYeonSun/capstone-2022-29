{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "029e97f2",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d239d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyrouge --upgrade\n",
    "# !pip install https://github.com/bheinzerling/pyrouge/archive/master.zip\n",
    "# !pip install pyrouge\n",
    "# !pip show pyrouge\n",
    "# !git clone https://github.com/andersjo/pyrouge.git\n",
    "# from pyrouge import Rouge155\n",
    "# !pyrouge_set_rouge_path 'pyrouge/tools/ROUGE-1.5.5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7f36f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install tensorboardX\n",
    "# !pip install easydict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245cdf0c",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26417124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('KorBertSum/src')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from models import data_loader, model_builder\n",
    "from models.model_builder import Summarizer\n",
    "from others.logging import logger, init_logger\n",
    "from models.data_loader import load_dataset\n",
    "from transformers import BertConfig, BertTokenizer\n",
    "from tensorboardX import SummaryWriter\n",
    "from models.reporter import ReportMgr\n",
    "from models.stats import Statistics\n",
    "import easydict\n",
    "from multiprocessing.dummy import Pool as ThreadPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4248808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _tally_parameters(model):\n",
    "    n_params = sum([p.nelement() for p in model.parameters()])\n",
    "    return n_params\n",
    "\n",
    "def build_trainer(args, device_id, model,\n",
    "                  optim):\n",
    "    \"\"\"\n",
    "    Simplify `Trainer` creation based on user `opt`s*\n",
    "    Args:\n",
    "        opt (:obj:`Namespace`): user options (usually from argument parsing)\n",
    "        model (:obj:`onmt.models.NMTModel`): the model to train\n",
    "        fields (dict): dict of fields\n",
    "        optim (:obj:`onmt.utils.Optimizer`): optimizer used during training\n",
    "        data_type (str): string describing the type of data\n",
    "            e.g. \"text\", \"img\", \"audio\"\n",
    "        model_saver(:obj:`onmt.models.ModelSaverBase`): the utility object\n",
    "            used to save the model\n",
    "    \"\"\"\n",
    "    device = \"cpu\" if args.visible_gpus == '-1' else \"cuda\"\n",
    "\n",
    "\n",
    "    grad_accum_count = args.accum_count\n",
    "    n_gpu = args.world_size\n",
    "\n",
    "    if device_id >= 0:\n",
    "        gpu_rank = int(args.gpu_ranks[device_id])\n",
    "    else:\n",
    "        gpu_rank = 0\n",
    "        n_gpu = 0\n",
    "\n",
    "    print('gpu_rank %d' % gpu_rank)\n",
    "\n",
    "    tensorboard_log_dir = args.model_path\n",
    "\n",
    "    writer = SummaryWriter(tensorboard_log_dir, comment=\"Unmt\")\n",
    "\n",
    "    report_manager = ReportMgr(args.report_every, start_time=-1, tensorboard_writer=writer)\n",
    "\n",
    "    trainer = Trainer(args, model, optim, grad_accum_count, n_gpu, gpu_rank, report_manager)\n",
    "\n",
    "    # print(tr)\n",
    "    if (model):\n",
    "        n_params = _tally_parameters(model)\n",
    "        logger.info('* number of parameters: %d' % n_params)\n",
    "\n",
    "    return trainer\n",
    "\n",
    "class Trainer(object):\n",
    "    \"\"\"\n",
    "    Class that controls the training process.\n",
    "\n",
    "    Args:\n",
    "            model(:py:class:`onmt.models.model.NMTModel`): translation model\n",
    "                to train\n",
    "            train_loss(:obj:`onmt.utils.loss.LossComputeBase`):\n",
    "               training loss computation\n",
    "            valid_loss(:obj:`onmt.utils.loss.LossComputeBase`):\n",
    "               training loss computation\n",
    "            optim(:obj:`onmt.utils.optimizers.Optimizer`):\n",
    "               the optimizer responsible for update\n",
    "            trunc_size(int): length of truncated back propagation through time\n",
    "            shard_size(int): compute loss in shards of this size for efficiency\n",
    "            data_type(string): type of the source input: [text|img|audio]\n",
    "            norm_method(string): normalization methods: [sents|tokens]\n",
    "            grad_accum_count(int): accumulate gradients this many times.\n",
    "            report_manager(:obj:`onmt.utils.ReportMgrBase`):\n",
    "                the object that creates reports, or None\n",
    "            model_saver(:obj:`onmt.models.ModelSaverBase`): the saver is\n",
    "                used to save a checkpoint.\n",
    "                Thus nothing will be saved if this parameter is None\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,  args, model,  optim,\n",
    "                  grad_accum_count=1, n_gpu=1, gpu_rank=1,\n",
    "                  report_manager=None):\n",
    "        # Basic attributes.\n",
    "        self.args = args\n",
    "        self.save_checkpoint_steps = args.save_checkpoint_steps\n",
    "        self.model = model\n",
    "        self.optim = optim\n",
    "        self.grad_accum_count = grad_accum_count\n",
    "        self.n_gpu = n_gpu\n",
    "        self.gpu_rank = gpu_rank\n",
    "        self.report_manager = report_manager\n",
    "\n",
    "        self.loss = torch.nn.BCELoss(reduction='none')\n",
    "        assert grad_accum_count > 0\n",
    "        # Set model in training mode.\n",
    "        if (model):\n",
    "            self.model.train()\n",
    "            \n",
    "    def summ(self, test_iter, step, cal_lead=False, cal_oracle=False):\n",
    "          \"\"\" Validate model.\n",
    "              valid_iter: validate data iterator\n",
    "          Returns:\n",
    "              :obj:`nmt.Statistics`: validation loss statistics\n",
    "          \"\"\"\n",
    "          # Set model in validating mode.\n",
    "          def _get_ngrams(n, text):\n",
    "              ngram_set = set()\n",
    "              text_length = len(text)\n",
    "              max_index_ngram_start = text_length - n\n",
    "              for i in range(max_index_ngram_start + 1):\n",
    "                  ngram_set.add(tuple(text[i:i + n]))\n",
    "              return ngram_set\n",
    "\n",
    "          def _block_tri(c, p):\n",
    "              tri_c = _get_ngrams(3, c.split())\n",
    "              for s in p:\n",
    "                  tri_s = _get_ngrams(3, s.split())\n",
    "                  if len(tri_c.intersection(tri_s))>0:\n",
    "                      return True\n",
    "              return False\n",
    "\n",
    "          if (not cal_lead and not cal_oracle):\n",
    "              self.model.eval()\n",
    "          stats = Statistics()\n",
    "\n",
    "          with torch.no_grad():\n",
    "              for batch in test_iter:\n",
    "                  src = batch.src\n",
    "                  labels = batch.labels\n",
    "                  segs = batch.segs\n",
    "                  clss = batch.clss\n",
    "                  mask = batch.mask\n",
    "                  mask_cls = batch.mask_cls\n",
    "\n",
    "                  if (cal_lead):\n",
    "                      selected_ids = [list(range(batch.clss.size(1)))] * batch.batch_size\n",
    "                  elif (cal_oracle):\n",
    "                      selected_ids = [[j for j in range(batch.clss.size(1)) if labels[i][j] == 1] for i in\n",
    "                                      range(batch.batch_size)]\n",
    "                  else:\n",
    "                      sent_scores, mask = self.model(src, segs, clss, mask, mask_cls)\n",
    "                      sent_scores = sent_scores + mask.float()\n",
    "                      sent_scores = sent_scores.cpu().data.numpy()\n",
    "                      selected_ids = np.argsort(-sent_scores, 1)\n",
    "          return selected_ids\n",
    "\n",
    "    def _gradient_accumulation(self, true_batchs, normalization, total_stats,\n",
    "                               report_stats):\n",
    "        if self.grad_accum_count > 1:\n",
    "            self.model.zero_grad()\n",
    "\n",
    "        for batch in true_batchs:\n",
    "            if self.grad_accum_count == 1:\n",
    "                self.model.zero_grad()\n",
    "\n",
    "            src = batch.src\n",
    "            labels = batch.labels\n",
    "            segs = batch.segs\n",
    "            clss = batch.clss\n",
    "            mask = batch.mask\n",
    "            mask_cls = batch.mask_cls\n",
    "\n",
    "            sent_scores, mask = self.model(src, segs, clss, mask, mask_cls)\n",
    "\n",
    "            loss = self.loss(sent_scores, labels.float())\n",
    "            loss = (loss*mask.float()).sum()\n",
    "            (loss/loss.numel()).backward()\n",
    "            # loss.div(float(normalization)).backward()\n",
    "\n",
    "            batch_stats = Statistics(float(loss.cpu().data.numpy()), normalization)\n",
    "\n",
    "\n",
    "            total_stats.update(batch_stats)\n",
    "            report_stats.update(batch_stats)\n",
    "\n",
    "            # 4. Update the parameters and statistics.\n",
    "            if self.grad_accum_count == 1:\n",
    "                # Multi GPU gradient gather\n",
    "                if self.n_gpu > 1:\n",
    "                    grads = [p.grad.data for p in self.model.parameters()\n",
    "                             if p.requires_grad\n",
    "                             and p.grad is not None]\n",
    "                    distributed.all_reduce_and_rescale_tensors(\n",
    "                        grads, float(1))\n",
    "                self.optim.step()\n",
    "\n",
    "        # in case of multi step gradient accumulation,\n",
    "        # update only after accum batches\n",
    "        if self.grad_accum_count > 1:\n",
    "            if self.n_gpu > 1:\n",
    "                grads = [p.grad.data for p in self.model.parameters()\n",
    "                         if p.requires_grad\n",
    "                         and p.grad is not None]\n",
    "                distributed.all_reduce_and_rescale_tensors(\n",
    "                    grads, float(1))\n",
    "            self.optim.step()\n",
    "            \n",
    "    def _save(self, step):\n",
    "        real_model = self.model\n",
    "        # real_generator = (self.generator.module\n",
    "        #                   if isinstance(self.generator, torch.nn.DataParallel)\n",
    "        #                   else self.generator)\n",
    "\n",
    "        model_state_dict = real_model.state_dict()\n",
    "        # generator_state_dict = real_generator.state_dict()\n",
    "        checkpoint = {\n",
    "            'model': model_state_dict,\n",
    "            # 'generator': generator_state_dict,\n",
    "            'opt': self.args,\n",
    "            'optim': self.optim,\n",
    "        }\n",
    "        checkpoint_path = os.path.join(self.args.model_path, 'model_step_%d.pt' % step)\n",
    "        logger.info(\"Saving checkpoint %s\" % checkpoint_path)\n",
    "        # checkpoint_path = '%s_step_%d.pt' % (FLAGS.model_path, step)\n",
    "        if (not os.path.exists(checkpoint_path)):\n",
    "            torch.save(checkpoint, checkpoint_path)\n",
    "            return checkpoint, checkpoint_path\n",
    "\n",
    "    def _start_report_manager(self, start_time=None):\n",
    "        \"\"\"\n",
    "        Simple function to start report manager (if any)\n",
    "        \"\"\"\n",
    "        if self.report_manager is not None:\n",
    "            if start_time is None:\n",
    "                self.report_manager.start()\n",
    "            else:\n",
    "                self.report_manager.start_time = start_time\n",
    "\n",
    "    def _maybe_gather_stats(self, stat):\n",
    "        \"\"\"\n",
    "        Gather statistics in multi-processes cases\n",
    "\n",
    "        Args:\n",
    "            stat(:obj:onmt.utils.Statistics): a Statistics object to gather\n",
    "                or None (it returns None in this case)\n",
    "\n",
    "        Returns:\n",
    "            stat: the updated (or unchanged) stat object\n",
    "        \"\"\"\n",
    "        if stat is not None and self.n_gpu > 1:\n",
    "            return Statistics.all_gather_stats(stat)\n",
    "        return stat\n",
    "\n",
    "    def _maybe_report_training(self, step, num_steps, learning_rate,\n",
    "                               report_stats):\n",
    "        \"\"\"\n",
    "        Simple function to report training stats (if report_manager is set)\n",
    "        see `onmt.utils.ReportManagerBase.report_training` for doc\n",
    "        \"\"\"\n",
    "        if self.report_manager is not None:\n",
    "            return self.report_manager.report_training(\n",
    "                step, num_steps, learning_rate, report_stats,\n",
    "                multigpu=self.n_gpu > 1)\n",
    "        \n",
    "    def _report_step(self, learning_rate, step, train_stats=None,\n",
    "                     valid_stats=None):\n",
    "        \"\"\"\n",
    "        Simple function to report stats (if report_manager is set)\n",
    "        see `onmt.utils.ReportManagerBase.report_step` for doc\n",
    "        \"\"\"\n",
    "        if self.report_manager is not None:\n",
    "            return self.report_manager.report_step(\n",
    "                learning_rate, step, train_stats=train_stats,\n",
    "                valid_stats=valid_stats)\n",
    "\n",
    "    def _maybe_save(self, step):\n",
    "        \"\"\"\n",
    "        Save the model if a model saver is set\n",
    "        \"\"\"\n",
    "        if self.model_saver is not None:\n",
    "            self.model_saver.maybe_save(step)\n",
    "\n",
    "class BertData():\n",
    "    def __init__(self):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "        self.sep_vid = self.tokenizer.vocab['[SEP]']\n",
    "        self.cls_vid = self.tokenizer.vocab['[CLS]']\n",
    "        self.pad_vid = self.tokenizer.vocab['[PAD]']\n",
    "\n",
    "    def preprocess(self, src):\n",
    "\n",
    "        if (len(src) == 0):\n",
    "            return None\n",
    "\n",
    "        original_src_txt = [' '.join(s) for s in src]\n",
    "        idxs = [i for i, s in enumerate(src) if (len(s) > 1)]\n",
    "\n",
    "        src = [src[i][:2000] for i in idxs]\n",
    "        src = src[:1000]\n",
    "\n",
    "        if (len(src) < 3):\n",
    "            return None\n",
    "\n",
    "        src_txt = [' '.join(sent) for sent in src]\n",
    "        text = ' [SEP] [CLS] '.join(src_txt)\n",
    "        src_subtokens = self.tokenizer.tokenize(text)\n",
    "        src_subtokens = src_subtokens[:510]\n",
    "        src_subtokens = ['[CLS]'] + src_subtokens + ['[SEP]']\n",
    "\n",
    "        src_subtoken_idxs = self.tokenizer.convert_tokens_to_ids(src_subtokens)\n",
    "        _segs = [-1] + [i for i, t in enumerate(src_subtoken_idxs) if t == self.sep_vid]\n",
    "        segs = [_segs[i] - _segs[i - 1] for i in range(1, len(_segs))]\n",
    "        segments_ids = []\n",
    "        for i, s in enumerate(segs):\n",
    "            if (i % 2 == 0):\n",
    "                segments_ids += s * [0]\n",
    "            else:\n",
    "                segments_ids += s * [1]\n",
    "        cls_ids = [i for i, t in enumerate(src_subtoken_idxs) if t == self.cls_vid]\n",
    "        labels = None\n",
    "        src_txt = [original_src_txt[i] for i in idxs]\n",
    "        tgt_txt = None\n",
    "        return src_subtoken_idxs, labels, segments_ids, cls_ids, src_txt, tgt_txt\n",
    "    \n",
    "def _lazy_dataset_loader(pt_file):\n",
    "  yield  pt_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ece4fd",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "babde425",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-16 16:02:44,689 INFO] Loading checkpoint from ../models/bert_trans_1/model_step_65000.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Summarizer(\n",
       "  (bert): Bert(\n",
       "    (model): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder): TransformerInterEncoder(\n",
       "    (pos_emb): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer_inter): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (w_2): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=768, out_features=512, bias=True)\n",
       "          (w_2): Linear(in_features=512, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (wo): Linear(in_features=768, out_features=1, bias=True)\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = easydict.EasyDict({\n",
    "    \"encoder\":'transformer', ## classifier or transformer\n",
    "    \"mode\":'test',\n",
    "    \"bert_data_path\":'../bert_data/korean',\n",
    "    \"model_path\":'../models/bert_trans_1', ## check\n",
    "    \"result_path\":'../results',\n",
    "    \"temp_dir\":'../temp',\n",
    "    \"batch_size\":1000,\n",
    "    \"use_interval\":True,\n",
    "    \"hidden_size\":128,\n",
    "    \"ff_size\":512,\n",
    "    \"heads\":4,\n",
    "    \"inter_layers\":2,\n",
    "    \"rnn_size\":512,\n",
    "    \"param_init\":0,\n",
    "    \"param_init_glorot\":True,\n",
    "    \"dropout\":0.1,\n",
    "    \"optim\":'adamW', ## check\n",
    "    \"lr\":2e-3,\n",
    "    \"report_every\":1,\n",
    "    \"save_checkpoint_steps\":100,\n",
    "    \"block_trigram\":True,\n",
    "    \"recall_eval\":False,\n",
    "    \n",
    "    \"accum_count\":1,\n",
    "    \"world_size\":1,\n",
    "    \"visible_gpus\":'0', # 0 = gpu, -1 = cpu ## check\n",
    "    \"gpu_ranks\":'0',\n",
    "    \"log_file\":'../logs/train_trans_1.txt', ## check\n",
    "    \"test_from\":'../models/bert_trans_1/model_step_65000.pt' ## check\n",
    "})\n",
    "model_flags = ['hidden_size', 'ff_size', 'heads', 'inter_layers','encoder','ff_actv', 'use_interval','rnn_size']\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "# Model Load\n",
    "# test(args, input_data, -1, '', None)\n",
    "pt = ''\n",
    "step = None\n",
    "\n",
    "init_logger(args.log_file)\n",
    "device = \"cpu\" if args.visible_gpus == '-1' else \"cuda\"\n",
    "device_id = 0 if device == \"cuda\" else -1\n",
    "\n",
    "cp = args.test_from\n",
    "try:\n",
    "    step = int(cp.split('.')[-2].split('_')[-1])\n",
    "except:\n",
    "    step = 0\n",
    "\n",
    "device = \"cpu\" if args.visible_gpus == '-1' else \"cuda\"\n",
    "if (pt != ''):\n",
    "    test_from = pt\n",
    "else:\n",
    "    test_from = args.test_from\n",
    "logger.info('Loading checkpoint from %s' % test_from)\n",
    "checkpoint = torch.load(test_from, map_location=lambda storage, loc: storage)\n",
    "opt = vars(checkpoint['opt'])\n",
    "for k in opt.keys():\n",
    "    if (k in model_flags):\n",
    "        setattr(args, k, opt[k])\n",
    "\n",
    "config = BertConfig.from_pretrained('bert-base-multilingual-cased')\n",
    "model = Summarizer(args, device, load_pretrained_bert=False, bert_config = config)\n",
    "model.load_cp(checkpoint)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff159217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, input_list):\n",
    "  test_iter = data_loader.Dataloader(args, _lazy_dataset_loader(input_list),\n",
    "                                args.batch_size, device,\n",
    "                                shuffle=False, is_test=True)\n",
    "  trainer = build_trainer(args, device_id, model, None)\n",
    "  result = trainer.summ(test_iter, step)\n",
    "  return result, input_list\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "def txt2input(text):\n",
    "  data = list(filter(None, text.split('\\n')))\n",
    "  bertdata = BertData()\n",
    "  txt_data = bertdata.preprocess(data)\n",
    "  data_dict = {\"src\":txt_data[0],\n",
    "               \"labels\":[0,1,2],\n",
    "               \"segs\":txt_data[2],\n",
    "               \"clss\":txt_data[3],\n",
    "               \"src_txt\":txt_data[4],\n",
    "               \"tgt_txt\":None}\n",
    "  input_data = []\n",
    "  input_data.append(data_dict)\n",
    "  return input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94f7f88",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e47c7df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>journal</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>627cdd4d7f98dd6342b32231</td>\n",
       "      <td>최인아 객원논설위원·최인아책방 대표\\n\\n이제 마스크도 벗나 했지만 앞으로도 얼마간...</td>\n",
       "      <td>2022-04-16</td>\n",
       "      <td>동아일보</td>\n",
       "      <td>이제 마스크도 벗나 했지만 앞으로도 얼마간은 더 써야 하는 모양이다. 그래도 다음 ...</td>\n",
       "      <td>‘존재의 이유’를 말해 보라[동아광장/최인아]</td>\n",
       "      <td>https://www.donga.com/news/Opinion/article/all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>627cdd4d7f98dd6342b32249</td>\n",
       "      <td>‘엄선한 원두와 뛰어난 기술력의 조화, 황금 비율 커피 ‘맥심 모카골드’\\n\\n커피...</td>\n",
       "      <td>2022-04-20</td>\n",
       "      <td>동아일보</td>\n",
       "      <td>대한민국 국민이라면 누구나 아는 노란색 커피믹스가 있다. 바로 맥심 모카골드다. 맥...</td>\n",
       "      <td>‘홈카페’하면 맥심… 모카골드와 커피 한잔의 여유</td>\n",
       "      <td>https://www.donga.com/news/Economy/article/all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>627cdd4d7f98dd6342b3229f</td>\n",
       "      <td>SPC그룹 계열사 비알코리아가 운영하는 던킨이 ‘뉴웨이브 프로젝트’의 일환으로 고메...</td>\n",
       "      <td>2022-04-20</td>\n",
       "      <td>동아일보</td>\n",
       "      <td>SPC그룹 계열사 비알코리아가 운영하는 던킨이 ‘뉴웨이브 프로젝트’의 일환으로 고메...</td>\n",
       "      <td>고메 도넛, 프리미엄 디저트로 자리잡아</td>\n",
       "      <td>https://www.donga.com/news/Economy/article/all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>627cdd4d7f98dd6342b32313</td>\n",
       "      <td>연구진이 개발한 VR 시스템 ‘게임체인지’ 화면. 커피를 요청하거나 버스에 탑승하는...</td>\n",
       "      <td>2022-04-18</td>\n",
       "      <td>동아일보</td>\n",
       "      <td>연구진이 개발한 VR 시스템 ‘게임체인지’ 화면. 커피를 요청하거나 버스에 탑승하는...</td>\n",
       "      <td>‘마음의 병’ 고치러 가상현실 로그인… 실제 치료효과 입증됐다</td>\n",
       "      <td>https://www.donga.com/news/It/article/all/2022...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>627cdd4d7f98dd6342b323a9</td>\n",
       "      <td>서울 중구 덕수궁 석조전에서 커피를 맛보며 밤하늘을 감상하는 야간 체험 행사가 열린...</td>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>동아일보</td>\n",
       "      <td>서울 중구 덕수궁 석조전에서 커피를 맛보며 밤하늘을 감상하는 야간 체험 행사가 열린...</td>\n",
       "      <td>커피 마시며 덕수궁 밤하늘 감상… 내달 3일부터 ‘밤의 석조전’ 행사</td>\n",
       "      <td>https://www.donga.com/news/Culture/article/all...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  \\\n",
       "0  627cdd4d7f98dd6342b32231   \n",
       "1  627cdd4d7f98dd6342b32249   \n",
       "2  627cdd4d7f98dd6342b3229f   \n",
       "3  627cdd4d7f98dd6342b32313   \n",
       "4  627cdd4d7f98dd6342b323a9   \n",
       "\n",
       "                                             content        date journal  \\\n",
       "0  최인아 객원논설위원·최인아책방 대표\\n\\n이제 마스크도 벗나 했지만 앞으로도 얼마간...  2022-04-16    동아일보   \n",
       "1  ‘엄선한 원두와 뛰어난 기술력의 조화, 황금 비율 커피 ‘맥심 모카골드’\\n\\n커피...  2022-04-20    동아일보   \n",
       "2  SPC그룹 계열사 비알코리아가 운영하는 던킨이 ‘뉴웨이브 프로젝트’의 일환으로 고메...  2022-04-20    동아일보   \n",
       "3  연구진이 개발한 VR 시스템 ‘게임체인지’ 화면. 커피를 요청하거나 버스에 탑승하는...  2022-04-18    동아일보   \n",
       "4  서울 중구 덕수궁 석조전에서 커피를 맛보며 밤하늘을 감상하는 야간 체험 행사가 열린...  2022-04-21    동아일보   \n",
       "\n",
       "                                             summary  \\\n",
       "0  이제 마스크도 벗나 했지만 앞으로도 얼마간은 더 써야 하는 모양이다. 그래도 다음 ...   \n",
       "1  대한민국 국민이라면 누구나 아는 노란색 커피믹스가 있다. 바로 맥심 모카골드다. 맥...   \n",
       "2  SPC그룹 계열사 비알코리아가 운영하는 던킨이 ‘뉴웨이브 프로젝트’의 일환으로 고메...   \n",
       "3  연구진이 개발한 VR 시스템 ‘게임체인지’ 화면. 커피를 요청하거나 버스에 탑승하는...   \n",
       "4  서울 중구 덕수궁 석조전에서 커피를 맛보며 밤하늘을 감상하는 야간 체험 행사가 열린...   \n",
       "\n",
       "                                     title  \\\n",
       "0               ‘존재의 이유’를 말해 보라[동아광장/최인아]    \n",
       "1             ‘홈카페’하면 맥심… 모카골드와 커피 한잔의 여유    \n",
       "2                   고메 도넛, 프리미엄 디저트로 자리잡아    \n",
       "3      ‘마음의 병’ 고치러 가상현실 로그인… 실제 치료효과 입증됐다    \n",
       "4  커피 마시며 덕수궁 밤하늘 감상… 내달 3일부터 ‘밤의 석조전’ 행사    \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.donga.com/news/Opinion/article/all...  \n",
       "1  https://www.donga.com/news/Economy/article/all...  \n",
       "2  https://www.donga.com/news/Economy/article/all...  \n",
       "3  https://www.donga.com/news/It/article/all/2022...  \n",
       "4  https://www.donga.com/news/Culture/article/all...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### DB 검색어 데이터셋 가져오기\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "res = requests.get('http://ec2-3-34-47-218.ap-northeast-2.compute.amazonaws.com:5000/news?query=' + '커피') # 검색어 바꾸기\n",
    "news_dict = json.loads(res.text) # list 안에 딕셔너리 형태\n",
    "\n",
    "col_name = [\"_id\", \"content\", \"date\", \"journal\", \"summary\", \"title\", \"url\"]\n",
    "news_df = pd.DataFrame(news_dict, columns=col_name)\n",
    "\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d7664dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:00<00:00, 5172.19it/s]\n"
     ]
    }
   ],
   "source": [
    "### 동아일보 들여쓰기\n",
    "from tqdm import tqdm\n",
    "from more_itertools import locate\n",
    "\n",
    "new_list = []\n",
    "\n",
    "for i in tqdm(range(len(news_df))):\n",
    "    idx = news_df.loc[i]['_id']\n",
    "    test_txt = news_df.loc[i]['content']\n",
    "    date = news_df.loc[i]['date']\n",
    "    journal = news_df.loc[i]['journal']\n",
    "    title = news_df.loc[i]['title']\n",
    "    url = news_df.loc[i]['url']\n",
    "        \n",
    "    if journal == '동아일보':\n",
    "        # 문장 끝 부호 인덱스 구하기\n",
    "        pos_1 = list(locate(test_txt, (lambda x: x == \".\")))\n",
    "        pos_2 = list(locate(test_txt, (lambda x: x == \"?\")))\n",
    "        pos_3 = list(locate(test_txt, (lambda x: x == \"!\")))\n",
    "\n",
    "        pos = (pos_1 + pos_2 + pos_3)\n",
    "        pos.sort()\n",
    "        \n",
    "        # 문장별 리스트로 쪼개기\n",
    "        txts = []\n",
    "        for i in range(len(pos)):\n",
    "            if i == 0:\n",
    "                txts.append(test_txt[:(pos[i]+1)])\n",
    "            elif i == (len(pos)-1):\n",
    "                txts.append(test_txt[(pos[i-1]+1):(pos[i]+1)])\n",
    "                txts.append(test_txt[(pos[i]+1):])\n",
    "            else:\n",
    "                txts.append(test_txt[(pos[i-1]+1):(pos[i]+1)])\n",
    "                \n",
    "        # \\n 추가\n",
    "        # 쪼개서 추가하는 이유.. 확인하고 바로 \\n 추가하면 인덱스가 달라져서..\n",
    "        txt = \"\"\n",
    "        for i in range(1, len(txts)):\n",
    "            if len(txts[i]) == 0:\n",
    "                continue\n",
    "            elif txts[i][0] != \" \":\n",
    "                txts[i - 1] += \"\\n\\n\"\n",
    "\n",
    "        # 문장 하나로 합치기\n",
    "        for i in range(len(txts)):\n",
    "            txt += txts[i]\n",
    "        \n",
    "        # Df에서 바로 변경하고 싶었지만, 변경되지 않아서 새로 만듦\n",
    "        new_list.append(\n",
    "            {\n",
    "                \"_id\" : idx,\n",
    "                \"content\" : txt,\n",
    "                \"date\" : date,\n",
    "                \"journal\" : journal,\n",
    "                \"summary\" : \"\",\n",
    "                \"title\" : title,\n",
    "                \"url\" : url\n",
    "            }\n",
    "        )\n",
    "    else: # 한겨레일 때\n",
    "        new_list.append(\n",
    "            {\n",
    "                \"_id\" : idx,\n",
    "                \"content\" : test_txt,\n",
    "                \"date\" : date,\n",
    "                \"journal\" : journal,\n",
    "                \"summary\" : \"\",\n",
    "                \"title\" : title,\n",
    "                \"url\" : url\n",
    "            }\n",
    "        )\n",
    "\n",
    "col_name = [\"_id\", \"content\", \"date\", \"journal\", \"summary\", \"title\", \"url\"]\n",
    "news_df_test = pd.DataFrame(new_list, columns=col_name)\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "### 리스트 생성\n",
    "idxs = news_df_test['_id'].tolist()\n",
    "texts = news_df_test['content'].tolist()\n",
    "idx_text = list(zip(idxs, texts))\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "# # 기준 정하기\n",
    "# print(len('박임근 기자 hanjeoung990111@kookmin.ac.kr'))\n",
    "# print(len('지난해 3월 만경강 도보여행길 걷기에 앞서 발원지인 밤샘에서 촬영한 모습. 박영환씨 제공'))\n",
    "# 논문에서 50 미만 제거 함\n",
    "\n",
    "# 문자열 길이 확인 및 제거 & 기자 및 이메일 제거\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "for i in tqdm(range(len(idx_text))):\n",
    "    idx_text[i] = list(idx_text[i])\n",
    "    if (idx_text[i][1] != \"\"):\n",
    "        if (isinstance(idx_text[i][1], str)):\n",
    "            text_list = idx_text[i][1].split('\\n')\n",
    "            re_text = ''\n",
    "\n",
    "            for text in (text_list):\n",
    "                if len(text) > 50:\n",
    "                    text = re.sub(r\"([\\w\\.-]+)@([\\w\\.-]+)(\\.[\\w\\.]+)\", \"\", text) # 이메일 검사\n",
    "\n",
    "                    if \" 기자\" in text: # 기자 검사\n",
    "                        repoter_check = text.split(\" \")\n",
    "                        while \"기자\" in repoter_check:\n",
    "                            index = repoter_check.index(\"기자\")\n",
    "                            del repoter_check[index]\n",
    "                            del repoter_check[index-1]\n",
    "                        text = ' '.join(r for r in repoter_check)\n",
    "\n",
    "                    re_text += (text + '\\n')\n",
    "\n",
    "            idx_text[i][1] = re_text\n",
    "        \n",
    "    else:\n",
    "        idx_text[i][1] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6854c4dc",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "acf6a933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plink failed to import tkinter.\n"
     ]
    }
   ],
   "source": [
    "## DB 연결\n",
    "\n",
    "from bson.objectid import ObjectId\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient(\"mongodb+srv://BaekYeonsun:hello12345@cluster.3dypr.mongodb.net/database?retryWrites=true&w=majority\")\n",
    "collection = client.database.news\n",
    "\n",
    "# collection.update_one({'_id': ObjectId('627cdd2c7f98dd6342b32229')}, {'$set': {'summary':'test'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c53c3a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def inference(texts):\n",
    "    time.sleep(1)\n",
    "    idx = texts[0]\n",
    "    text = texts[1]\n",
    "    \n",
    "    if text == \"\" or pd.isna(text):\n",
    "        collection.update_one({'_id': ObjectId(idx)}, {'$set': {'summary':''}})\n",
    "    else:\n",
    "        if len(text.split('\\n')) <= 3: # 원문 기사가 짧은 경우. txt2input에서 none 타입이 됨\n",
    "            collection.update_one({'_id': ObjectId(idx)}, {'$set': {'summary': text}})\n",
    "        else:\n",
    "            input_data = txt2input(text)\n",
    "            sum_list = test(args, input_data)\n",
    "            result = [list(filter(None, text.split('\\n')))[i] for i in sum_list[0][0][:2]]\n",
    "            try:\n",
    "                summary = (result[0] + \" \" + result[1])\n",
    "                collection.update_one({'_id': ObjectId(idx)}, {'$set': {'summary': summary}})\n",
    "            except:\n",
    "                summary = (result[0])\n",
    "                collection.update_one({'_id': ObjectId(idx)}, {'$set': {'summary': summary}})\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b621026a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1/75 [00:01<01:15,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-16 16:18:39,514 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:18:40,642 INFO] * number of parameters: 184162049\n",
      "  9%|▉         | 7/75 [00:17<02:50,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-16 16:18:41,034 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:18:42,401 INFO] * number of parameters: 184162049\n",
      " 11%|█         | 8/75 [00:21<03:05,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-16 16:18:42,427 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:18:42,609 INFO] * number of parameters: 184162049\n",
      " 12%|█▏        | 9/75 [00:24<03:04,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-16 16:18:44,470 INFO] * number of parameters: 184162049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 11/75 [00:25<02:02,  1.92s/it][2022-05-16 16:18:44,609 INFO] * number of parameters: 184162049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-16 16:18:44,966 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:18:45,497 INFO] * number of parameters: 184162049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 12/75 [00:27<01:56,  1.86s/it][2022-05-16 16:18:45,605 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:18:45,635 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:18:46,181 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:18:46,219 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:18:46,339 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:18:47,823 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:18:47,843 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:18:47,908 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:18:47,956 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:18:48,154 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:18:48,161 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:18:48,368 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:18:48,941 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:18:48,962 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:18:49,543 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:18:50,115 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:18:51,113 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:18:51,116 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:18:51,605 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:18:51,671 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:18:51,769 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:18:52,373 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:18:52,388 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:18:52,419 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:18:52,421 INFO] * number of parameters: 184162049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-16 16:18:52,875 INFO] * number of parameters: 184162049\n",
      " 17%|█▋        | 13/75 [00:27<01:35,  1.53s/it][2022-05-16 16:18:52,877 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:18:53,739 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:18:53,811 INFO] * number of parameters: 184162049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n",
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-16 16:18:54,184 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:18:54,186 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:18:54,196 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:18:54,697 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:18:54,706 INFO] * number of parameters: 184162049\n",
      " 19%|█▊        | 14/75 [00:38<04:14,  4.18s/it][2022-05-16 16:18:54,708 INFO] * number of parameters: 184162049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n",
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-16 16:18:54,718 INFO] * number of parameters: 184162049\n",
      " 21%|██▏       | 16/75 [00:46<03:47,  3.85s/it][2022-05-16 16:18:55,122 INFO] * number of parameters: 184162049\n",
      " 23%|██▎       | 17/75 [00:47<02:52,  2.98s/it][2022-05-16 16:18:56,166 INFO] * number of parameters: 184162049\n",
      " 24%|██▍       | 18/75 [00:50<02:44,  2.88s/it][2022-05-16 16:19:12,064 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:19:12,655 INFO] * number of parameters: 184162049\n",
      " 75%|███████▍  | 56/75 [00:54<00:03,  5.20it/s][2022-05-16 16:19:22,114 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:19:22,125 INFO] * number of parameters: 184162049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 57/75 [00:56<00:05,  3.16it/s][2022-05-16 16:19:23,538 INFO] * number of parameters: 184162049\n",
      " 79%|███████▊  | 59/75 [00:57<00:05,  2.95it/s][2022-05-16 16:19:24,704 INFO] * number of parameters: 184162049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n",
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-16 16:19:25,221 INFO] * number of parameters: 184162049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-16 16:19:26,096 INFO] * number of parameters: 184162049\n",
      " 83%|████████▎ | 62/75 [01:00<00:07,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n",
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-16 16:19:28,541 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:19:28,796 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:19:28,798 INFO] * number of parameters: 184162049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n",
      "gpu_rank 0\n",
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-16 16:19:28,941 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:19:28,980 INFO] * number of parameters: 184162049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n",
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-16 16:19:30,757 INFO] * number of parameters: 184162049\n",
      " 84%|████████▍ | 63/75 [01:05<00:14,  1.25s/it][2022-05-16 16:19:31,393 INFO] * number of parameters: 184162049\n",
      " 85%|████████▌ | 64/75 [01:05<00:11,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n",
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-16 16:19:33,142 INFO] * number of parameters: 184162049\n",
      "[2022-05-16 16:19:33,743 INFO] * number of parameters: 184162049\n",
      " 91%|█████████ | 68/75 [01:06<00:04,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n",
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-16 16:19:34,077 INFO] * number of parameters: 184162049\n",
      " 92%|█████████▏| 69/75 [01:07<00:03,  1.64it/s][2022-05-16 16:19:34,084 INFO] * number of parameters: 184162049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n",
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-16 16:19:34,890 INFO] * number of parameters: 184162049\n",
      " 93%|█████████▎| 70/75 [01:08<00:04,  1.19it/s][2022-05-16 16:19:35,391 INFO] * number of parameters: 184162049\n",
      "100%|██████████| 75/75 [01:10<00:00,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ThreadPool 방식\n",
    "pool = ThreadPool(50)\n",
    "\n",
    "for _ in tqdm(pool.imap_unordered(inference, idx_text), total=len(idx_text)):\n",
    "    pass\n",
    "    \n",
    "print(\"finish\")\n",
    "\n",
    "# pool.close()\n",
    "# pool.terminate()\n",
    "# pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "88696467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('627cdd4d7f98dd6342b32231'),\n",
       " 'content': '최인아 객원논설위원·최인아책방 대표\\n\\n이제 마스크도 벗나 했지만 앞으로도 얼마간은 더 써야 하는 모양이다. 그래도 다음 주부턴 사적 모임 인원과 영업시간 제한을 전면 해제하는 등 2년 넘게 유지돼 온 사회적 거리 두기가 끝이 난다. 휴∼ 다행이다. 그동안 참 힘들었다. 모두의 고생이 컸지만 특히 자영업자들은 죽을 맛이었다. 나 또한 책방을 시작한 지 7년 차 자영업자로 같은 사정에 처했고 어려움을 겪었다.요즘 책방들은 책만 팔지 않는다. 커피 등 음료도 판다는 뜻이 아니다. 그곳에선 책만 읽어서는 결코 알 수 없는 경험들을 다채롭게 제공한다. 당장 우리 책방만 해도 책을 낸 저자와 독자가 직접 만나는 북 토크는 기본이고 ‘파친코’ 등 영어로 쓰인 소설을 원문으로 읽거나 논어 같은 고전을 배우는 수업, 아티스트를 모셔서 평소엔 듣기 어려운 크리에이티브에 대한 이야기를 듣는 등 다채로운 콘텐츠를 마련하고 있다. 우리 고객 한 분은 이렇게 말할 정도다. 책방의 저녁은 날마다 새로운 프로그램이 펼쳐지는 뮤지컬 공연장 같다고.이런 일을 기획하고 준비하자면 많은 수고가 들어갈 텐데 왜 이런 일을 벌이는 걸까? 우선 생존의 이유가 있다. 우리는 디지털 시대를 살고 있지 않은가. 게다가 우리나라 사람들은 온라인에서 보내는 시간이 길다. 얼마 전 발표된 자료에 따르면 한국 사람들은 일생 동안 34년을 인터넷을 하며 보낸다고 한다. 미국, 영국, 프랑스 같은 나라들보다 훨씬 길다. 웬만한 필요는 거의 다 온라인상에서 충족되는 셈이다. 도서도 온라인 구매가 점점 더 늘고 있다. 사정이 이러니 우리 같은 오프라인 책방, 동네 책방들은 책 판매만으론 임차료 내기도 어렵다.이래서였을까? 내가 책방을 하기로 마음먹고 가장 오래 성심을 다해 준비한 것이 우리 책방의 ‘존재의 이유’를 찾는 일이었다. 책을 읽지 않는 시대에 책방이 웬 말이냐고, 적은 나이가 아닌데 이제 실패하면 만회할 시간조차 없다며 여러 사람들이 뜯어말렸다. 그랬음에도 시작한 일이니 여봐란듯이 잘해내고 싶었다. 하지만 잘하고 싶다고 해서 잘되는 건 아니지 않나. 방법을 찾아야 했는데 나는 이 질문들로부터 시작했다. 이미 세상엔 대형 서점도 있고 온라인 서점도 있고 또 동네 서점도 있다. 그런데 왜 또 우리 책방이 존재해야 할까? 고객은 왜 다른 데가 아니라 우리 책방을 찾아야 할까? 또 우리 책방이 존재함으로써 세상은 이전보다 조금이라도 더 나아지는가?실은, 광고회사 시절부터 이 생각을 갖고 일했다. 이 세상의 모든 기업, 제품, 브랜드는 ‘존재의 이유’를 말할 수 있어야 한다고, 고객이 왜 경쟁사 제품과 브랜드가 아니라 자신의 회사를 선택해야 하는지 말할 수 있어야 한다고 생각했다. 이제 내가 답할 차례였고 나는 다음과 같은 답에 도달했다. 아는 것이 힘이던 시대로부터 생각이 힘인 시대가 되었다, 세상을 바꾸는 새로운 가치들은 생각하는 힘으로부터 나오고 일터에서의 삶은 문제 해결의 연속이다, 우리가 사는 세상도 지금까지의 방식이 더는 통하지 않는 낯선 곳으로 나아가고 있다, 상상력, 창의력, 혹은 기획력, 문제 해결력 등 생각하는 힘이 그 어느 때보다 필요한데 우리 책방은 책을 통해 지금 시대에 가장 중요한 자산인 ‘생각의 힘’을 북돋우고 퍼뜨리겠다, 하나의 생각이 또 하나의 생각과 만나 깊고 다양한 생각의 숲을 이루는 ‘생각의 숲’이 되겠다고.이 문장들 속에 우리가 책방을 하는 이유, 고객이 우리 책방을 찾을 이유, 우리 책방이 세상에 존재해야 하는 이유가 담겨 있고 우리는 이 생각을 북극성으로 삼아 책을 큐레이션 하고 여러 프로그램을 궁리하고 있다. 아직까지 망하지 않고 7년째 하고 있는 걸 보면 우리 책방의 존재의 이유에 납득한 고객들이 많이 계시지 않나 짐작한다.이쯤에서 여러분께 한 가지를 제안한다. 일하는 분들, 특히 책임을 맡고 있거나 남보다 많은 기회를 누리는 분들은 스스로의 ‘존재의 이유’를 묻고 새로이 해 보시라. 겸손해지거나 착해지라는 뜻이 아니라 스마트해지라는 뜻에서다. 오래도록 잘하는 방법으로서, 또 기회를 준 많은 분들께 그 선택이 옳았음을 증명해 보이라는 뜻에서다. 물으면 찾게 되고 궁리하게 되며 새로이 하게 되는데 오래도록 잘하는 길은 종종 그 끝에서 열리기 때문이다. 특히 공직을 맡은 분들은 이 질문을 가까이 하시라. 하고많은 사람 중에 왜 내가 이 일을 맡아야 하고 맡을 만한지, 어떤 가치를 세상에 내놓을 것인지 깊이 자문자답해 보시라. 대한민국 국민 노릇 하기가 너무 힘들다. 부탁한다!최인아 객원논설위원·최인아책방 대표',\n",
       " 'date': '2022-04-16',\n",
       " 'journal': '동아일보',\n",
       " 'summary': '이제 마스크도 벗나 했지만 앞으로도 얼마간은 더 써야 하는 모양이다. 그래도 다음 주부턴 사적 모임 인원과 영업시간 제한을 전면 해제하는 등 2년 넘게 유지돼 온 사회적 거리 두기가 끝이 난다. 휴∼ 다행이다. 그동안 참 힘들었다. 모두의 고생이 컸지만 특히 자영업자들은 죽을 맛이었다. 나 또한 책방을 시작한 지 7년 차 자영업자로 같은 사정에 처했고 어려움을 겪었다. 요즘 책방들은 책만 팔지 않는다. 커피 등 음료도 판다는 뜻이 아니다. 그곳에선 책만 읽어서는 결코 알 수 없는 경험들을 다채롭게 제공한다. 당장 우리 책방만 해도 책을 낸 저자와 독자가 직접 만나는 북 토크는 기본이고 ‘파친코’ 등 영어로 쓰인 소설을 원문으로 읽거나 논어 같은 고전을 배우는 수업, 아티스트를 모셔서 평소엔 듣기 어려운 크리에이티브에 대한 이야기를 듣는 등 다채로운 콘텐츠를 마련하고 있다. 우리 고객 한 분은 이렇게 말할 정도다. 책방의 저녁은 날마다 새로운 프로그램이 펼쳐지는 뮤지컬 공연장 같다고.',\n",
       " 'title': '‘존재의 이유’를 말해 보라[동아광장/최인아] ',\n",
       " 'url': 'https://www.donga.com/news/Opinion/article/all/20220415/112906454/1'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.find_one({'_id': ObjectId(idx_text[0][0])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c165160",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Notebook)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
